# An example configuration file for Talos-Manager
# Remember, this is just an Ansible inventory file
# You can even use jinja2 templating in this file
cluster:
  children:
    controlplane:
      hosts:
        192.168.1.100:
          patch:
            machine:
              network:
                hostname: a

    worker:
      hosts:
        192.168.1.200:
          patch:
            machine:
              network:
                hostname: b
        # All nodes in range from 192.168.1.10 to 192.168.1.20
        # 192.168.1.[10:20]:

  vars:
    # Make sure you change the cluster name to something unique
    # WARNING! This will overwrite the existing context with this name in your talosconfig and kubeconfig
    cluster_name: example

    # IP or FQDN that will be used to reach the kubernetes API
    # This example sets the cluster endpoint to the ip of the first controlplane node
    cluster_endpoint: https://{{ groups['controlplane'][0] }}:6443

    # Add additional SANs to the TLS certificate
    # Controlplane IPs are automatically added
    # tls_sans:
    #   - kubernetes.example.com

    # Set the Talos/Kubernetes version to install
    # NOTE: Even if these variables are optional, it is highly recommened to set a version.
    # If you don't set a version, Talos-Manager will automatically upgrade your cluster to the newest version.
    # Patches override these values if their respective fields are set
    # Upgrades are automatic, if an image/version change is detected

    # talos_image: ghcr.io/siderolabs/installer # (Optional)
    talos_version: v1.7.5 # (Optional, but recommended)
    k8s_version: 1.30.1 # (Optional, but recommended)

    # Add additional patches to the selected category (Optional)
    # You can also define per machine patches by adding vars.patch to the node as demonstrated above
    patches: # (global | controlplane | worker) (Optional)
      global:
        machine:
          features:
            hostDNS:
              forwardKubeDNSToHost: true

      controlplane:
        cluster:
          allowSchedulingOnControlPlanes: true

      # worker: {}

    cilium: # Optional
      enabled: false
      # Cilium version to install
      version: 1.16.0 # Optional, but recommended

      # Namespace to install cilium to
      namespace: kube-system # Optional

      # Enable the default network policy
      # This will block traffic between pods except coredns, but allow traffic to the internet
      # kube-system and the specified cilium namespace are considered privileged namespaces,
      # all pods in these namespaces have no restrictions.
      # Pods running in the host network are also considered privileged, and have no restrictions.
      use_default_policy: false # Optional

      # Add additional values to the cilium helm chart
      helm_values: # Optional
        operator:
          replicas: 1
        # A simple load balancer similar to k3s's ServiceLB
        # To use this feature, you must set the loadBalancerClass to "io.cilium/node"
        nodeIPAM:
          enabled: true

    # Gzipped,Base64 encoded secrets file
    # You can generate this variable by running:
    # docker run ghcr.io/chickeniq/talos-manager gen-secrets
    secrets: ""

    # Enable FluxCD (Optional)
    # Only github repositories are currently supported
    fluxcd:
      enabled: false
      update: false # Update the FluxCD configuration every run (Optional)
      branch: main
      username: user
      repository: example
      path: clusters/example # Path to the FluxCD configuration.
      token: "" # GitHub PAT (Required permissions: Administration: RW, Contents: RW, Metadata: RO)
      sops: "" # Base64 encoded SOPS private key (Optional)
